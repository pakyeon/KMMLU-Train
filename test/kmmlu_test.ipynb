{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 모델의 데이터 타입을 설정\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# 모델을 4비트 양자화하여 로드할지 여부\n",
    "load_in_4bit = True\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"Bllossom/llama-3.2-Korean-Bllossom-3B\",\n",
    "    max_seq_length=200,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 경로\n",
    "checkpoint_path = \"./adapter/checkpoint-Construction\"\n",
    "\n",
    "# adapter 가중치 로드\n",
    "model.load_adapter(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(examples):\n",
    "    # 빈 리스트를 생성하여 프롬프트를 저장합니다.\n",
    "    prompts = []\n",
    "    \n",
    "    # 질문의 길이만큼 반복합니다.\n",
    "    for idx in range(len(examples['question'])):\n",
    "        # 각 질문에 대해 포맷된 프롬프트 문자열을 생성합니다.\n",
    "        prompt = f\"\"\"문제: {examples['question'][idx]}\n",
    "\n",
    "        선택지:\n",
    "        A. {examples['A'][idx]}\n",
    "        B. {examples['B'][idx]}\n",
    "        C. {examples['C'][idx]}\n",
    "        D. {examples['D'][idx]}\n",
    "\n",
    "        정답:\"\"\"\n",
    "        # 생성된 프롬프트를 리스트에 추가합니다.\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    # 배치 토크나이징을 수행하여 입력을 텐서로 변환합니다.\n",
    "    inputs = tokenizer(\n",
    "        prompts, \n",
    "        return_tensors=\"pt\",  # PyTorch 텐서 형식으로 반환\n",
    "        truncation=True,       # 길이가 max_length를 초과하는 경우 잘라냄\n",
    "        max_length=512,       # 최대 길이를 512로 설정\n",
    "        padding=True           # 배치 내의 모든 시퀀스 길이를 맞추기 위해 패딩 추가\n",
    "    )\n",
    "    \n",
    "    # 입력 텐서를 GPU로 이동시켜 반환합니다.\n",
    "    return {k: v.cuda() for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_outputs(outputs, prompt_lengths, examples, category):\n",
    "    # 결과를 저장할 빈 리스트를 생성합니다.\n",
    "    results = []\n",
    "    \n",
    "    # 선택지에 대한 번호 매핑을 정의합니다.\n",
    "    answer_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4}\n",
    "    \n",
    "    # 출력과 프롬프트 길이를 동시에 반복합니다.\n",
    "    for idx, (output, prompt_length) in enumerate(zip(outputs, prompt_lengths)):\n",
    "        # 토큰화된 출력을 디코딩하고, 프롬프트 길이 이후의 응답을 추출합니다.\n",
    "        response = tokenizer.decode(output, skip_special_tokens=True)[prompt_length:].strip().upper()\n",
    "        \n",
    "        # 예측된 답안을 저장할 변수를 초기화합니다.\n",
    "        predicted_answer = None\n",
    "        \n",
    "        # 가능한 답안(A, B, C, D) 중에서 응답에 포함된 답안을 찾습니다.\n",
    "        for answer in ['A', 'B', 'C', 'D']:\n",
    "            if answer in response:\n",
    "                predicted_answer = answer  # 응답에 포함된 답안을 저장합니다.\n",
    "                break\n",
    "        \n",
    "        # 예측된 답안을 숫자로 변환합니다.\n",
    "        predicted_answer_num = answer_mapping.get(predicted_answer, None)\n",
    "        \n",
    "        # 결과 리스트에 질문 ID, 예측된 답안, 정답, 정답 여부, 카테고리를 추가합니다.\n",
    "        results.append({\n",
    "            'question_id': idx,\n",
    "            'predicted': predicted_answer,  # 예측된 답안\n",
    "            'correct': examples['answer'][idx], # 정답\n",
    "            'is_correct': predicted_answer_num == examples['answer'][idx],  # 정답 여부\n",
    "            'category': category    # 질문 카테고리\n",
    "        })\n",
    "    \n",
    "    # 최종 결과 리스트를 반환합니다.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 모델 최적화 설정\n",
    "model.eval()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# KMMLU 데이터셋의 모든 카테고리 목록\n",
    "kmmlu_categories = [\n",
    "    \"Accounting\", \"Agricultural-Sciences\", \"Aviation-Engineering-and-Maintenance\", \"Biology\", \n",
    "    \"Chemical-Engineering\", \"Chemistry\", \"Civil-Engineering\", \"Computer-Science\", \"Construction\", \n",
    "    \"Criminal-Law\", \"Ecology\", \"Economics\", \"Education\", \"Electrical-Engineering\", \n",
    "    \"Electronics-Engineering\", \"Energy-Management\", \"Environmental-Science\", \"Fashion\", \"Food-Processing\", \n",
    "    \"Gas-Technology-and-Engineering\", \"Geomatics\", \"Health\", \"Industrial-Engineer\", \"Information-Technology\", \"Interior-Architecture-and-Design\", \n",
    "    \"Law\", \"Machine-Design-and-Manufacturing\", \"Management\", \"Maritime-Engineering\", \"Marketing\", \"Materials-Engineering\",\n",
    "    \"Mechanical-Engineering\", \"Nondestructive-Testing\", \"Patent\", \"Political-Science-and-Sociology\", \"Psychology\",\n",
    "    \"Public-Safety\", \"Railway-and-Automotive-Engineering\", \"Real-Estate\", \"Refrigerating-Machinery\", \"Social-Welfare\",\n",
    "    \"Taxation\", \"Telecommunications-and-Wireless-Technology\", \"Korean-History\", \"Math\"\n",
    "]\n",
    "\n",
    "# 데이터셋 평가를 위한 빈 리스트를 생성합니다.\n",
    "full_results = []\n",
    "\n",
    "# 추론 시간 측정\n",
    "start_time = time.time()\n",
    "\n",
    "# 각 카테고리별로 데이터셋을 평가합니다.\n",
    "for category in kmmlu_categories:\n",
    "    # KMMLU 데이터셋을 로드합니다.\n",
    "    dataset = load_dataset(\"HAERAE-HUB/KMMLU\", category)\n",
    "    test_dataset = dataset['test']  # 테스트 데이터셋 선택\n",
    "    \n",
    "    # 모델을 추론 모드로 설정합니다.\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    \n",
    "    # 테스트 데이터셋을 배치 사이즈만큼 반복합니다.\n",
    "    for i in tqdm(range(0, len(test_dataset), BATCH_SIZE), desc=f\"{category} 평가\"):\n",
    "        # 배치 데이터의 끝 인덱스를 계산합니다.\n",
    "        end_idx = min(i + BATCH_SIZE, len(test_dataset))\n",
    "        batch_data = test_dataset.select(range(i, end_idx))  # 현재 배치 데이터 선택\n",
    "        \n",
    "        # 배치 데이터를 전처리합니다.\n",
    "        inputs = prepare_batch(batch_data)\n",
    "\n",
    "        # 모델의 추론 모드에서 배치 추론을 수행합니다.\n",
    "        with torch.inference_mode():\n",
    "            outputs = model.generate(\n",
    "                **inputs,  # 전처리된 입력을 모델에 전달합니다.\n",
    "                max_new_tokens=1,  # 생성할 최대 토큰 수 설정\n",
    "                num_return_sequences=1,  # 반환할 시퀀스 수\n",
    "                temperature=0.7,  # 샘플링 온도 설정\n",
    "                use_cache=True,  # 캐시 사용 여부\n",
    "                do_sample=False,  # 샘플링 방식\n",
    "            )\n",
    "        \n",
    "        # 각 입력의 프롬프트 길이를 계산합니다.\n",
    "        prompt_lengths = [len(tokenizer.decode(input_ids, skip_special_tokens=True)) \n",
    "                          for input_ids in inputs['input_ids']]\n",
    "        \n",
    "        # 배치 결과를 처리합니다.\n",
    "        batch_results = process_batch_outputs(outputs, prompt_lengths, batch_data, category)\n",
    "        # 처리된 배치 결과를 전체 결과에 추가합니다.\n",
    "        full_results.extend(batch_results)\n",
    "        \n",
    "end_time = time.time()\n",
    "# 추론 시간 계산\n",
    "inference_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 분석을 위한 DataFrame을 생성합니다.\n",
    "df = pd.DataFrame(full_results)\n",
    "\n",
    "# 전체 정확도를 계산합니다.\n",
    "overall_accuracy = df['is_correct'].mean()\n",
    "\n",
    "# 카테고리별 메트릭스를 계산합니다.\n",
    "category_metrics = df.groupby('category')['is_correct'].agg([\n",
    "    ('accuracy', 'mean'),           # 각 카테고리의 정확도 계산\n",
    "    ('total_questions', 'count'),   # 각 카테고리의 총 문제 수 계산\n",
    "    ('correct_answers', 'sum')      # 각 카테고리의 정답 수 계산\n",
    "]).reset_index()  # 그룹화된 DataFrame의 인덱스를 기본 정수 인덱스로 재설정\n",
    "\n",
    "# 전체 정확도를 행으로 추가합니다.\n",
    "overall_row = pd.DataFrame({\n",
    "    '카테고리': '전체',               # 새로운 카테고리 이름\n",
    "    '평균 정확도': overall_accuracy,      # 전체 정확도\n",
    "    '총 문제 수': len(df),        # 총 문제 수\n",
    "    'correct_answers': df['is_correct'].sum(),  # 총 정답 수\n",
    "    'inference_time': inference_time # 총 추론 시간\n",
    "}, index=[0])  # 인덱스를 0으로 설정하여 DataFrame 생성\n",
    "\n",
    "# 전체 정확도 출력\n",
    "print(f\"\\n전체 정확도: {overall_accuracy:.2%}\")\n",
    "# 전체 문제 수 출력\n",
    "print(f\"총 문제 수: {len(df)}\")\n",
    "# 정답 수 출력\n",
    "print(f\"정답 수: {df['is_correct'].sum()}\")\n",
    "# 총 추론 시간 출력\n",
    "print(f\"추론 시간: {inference_time:.2f} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "df.to_csv('./result/kmmlu_full_evaluation_results_test.csv', index=False)\n",
    "category_metrics.to_csv('./result/kmmlu_category_metrics_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmmlu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
