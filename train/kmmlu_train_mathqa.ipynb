{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 GB of memory reserved.\n",
      "GPU = NVIDIA GeForce RTX 3060 Laptop GPU. Max memory = 6.0 GB.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 현재 사용 중인 GPU의 속성 정보 가져오기\n",
    "gpu_stats = torch.cuda.get_device_properties(0)  # 첫 번째 GPU 속성 정보를 가져옴\n",
    "\n",
    "# 현재 GPU에서 예약된 메모리 양을 GB 단위로 계산하여 출력\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")  # 예약된 메모리 양 출력\n",
    "\n",
    "# GPU의 전체 메모리 크기를 GB 단위로 계산하여 출력\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")  # GPU 이름과 최대 메모리 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Llama patching. Transformers = 4.46.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3060 Laptop GPU. Max memory: 6.0 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b84152fc3bc414b9666ac4c06c23c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bllossom/llama-3.2-Korean-Bllossom-3B does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "\n",
    "# 모델의 데이터 타입을 설정\n",
    "dtype = torch.bfloat16\n",
    "\n",
    "# 모델을 4비트 양자화하여 로드할지 여부\n",
    "load_in_4bit = True\n",
    "\n",
    "# 배치 크기 설정\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"Bllossom/llama-3.2-Korean-Bllossom-3B\",\n",
    "    max_seq_length=200,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"allenai/math_qa\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_options(dataset):\n",
    "    \n",
    "    processed_options = []\n",
    "        \n",
    "    for options_string in dataset[\"options\"]:\n",
    "        options = [\n",
    "            re.sub(r'^[a-e] \\) ', '', option.strip()).upper()\n",
    "            for option in re.findall(r'[a-e] \\) [^,]+', options_string)\n",
    "        ]\n",
    "        processed_options.append(options)\n",
    "        \n",
    "    return {\n",
    "        \"options\" : processed_options\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_data.map(preprocess_options, batched=True, num_proc=4,)\n",
    "eval_dataset = eval_data.map(preprocess_options, batched=True, num_proc=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Problem': \"the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\",\n",
       " 'Rationale': '\"explanation : t = 3 years r = 10 % td = ( bg × 100 ) / tr = ( 36 × 100 ) / ( 3 × 10 ) = 12 × 10 = rs . 120 td = ( pw × tr ) / 100 ⇒ 120 = ( pw × 3 × 10 ) / 100 ⇒ 1200 = pw × 3 pw = 1200 / 3 = rs . 400 answer : option a\"',\n",
       " 'options': ['RS . 400', 'RS . 300', 'RS . 500', 'RS . 350', 'NONE OF THESE'],\n",
       " 'correct': 'a',\n",
       " 'annotated_formula': 'divide(multiply(const_100, divide(multiply(36, const_100), multiply(3, 10))), multiply(3, 10))',\n",
       " 'linear_formula': 'multiply(n2,const_100)|multiply(n0,n1)|divide(#0,#1)|multiply(#2,const_100)|divide(#3,#1)|',\n",
       " 'category': 'gain'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "문제: {question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답:{answer}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(dataset):\n",
    "    question = dataset['Problem']\n",
    "    options_list = dataset['options']\n",
    "    answers = dataset['correct']\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for q, option, ans in zip(question, options_list, answers):\n",
    "        A = option[0]\n",
    "        B = option[1]\n",
    "        C = option[2]\n",
    "        D = option[3]\n",
    "        \n",
    "        ans = ans.upper()\n",
    "        \n",
    "        text = prompt_template.format(question=q, A=A, B=B, C=C, D=D, answer=ans)\n",
    "        text += EOS_TOKEN\n",
    "        result.append(text)\n",
    "        \n",
    "    return {\n",
    "        \"text\" : result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e69f0f4834d428f902f107f43b6a88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/29837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de03e2b0e929429fbd9b8d413d28ed0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4475 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset 에 preprocess_function 적용\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, num_proc=4, remove_columns=train_dataset.column_names)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True, num_proc=4, remove_columns=eval_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제: the banker ' s gain of a certain sum due 3 years hence at 10 % per annum is rs . 36 . what is the present worth ?\n",
      "A. RS . 400\n",
      "B. RS . 300\n",
      "C. RS . 500\n",
      "D. RS . 350\n",
      "정답:A<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=8,  # 0보다 큰 어떤 숫자도 선택 가능! 8, 16, 32, 64, 128이 권장됩니다.\n",
    "    lora_alpha=16,  # LoRA 알파 값을 설정합니다. # 튜토리얼은 16\n",
    "    lora_dropout=0.01,  # 드롭아웃을 지원합니다. # # Supports any, but = 0 is optimized\n",
    "    target_modules=[\n",
    "        \"q_proj\", # query\n",
    "        \"k_proj\", # key\n",
    "        \"v_proj\", # value\n",
    "        \"o_proj\", # output (어텐션 최종 출력)\n",
    "        \"gate_proj\", # 게이트 조절 시 사용\n",
    "        \"up_proj\", # 차원 확장 시 사용\n",
    "        \"down_proj\", # 차원 축소 시 사용\n",
    "    ],  # 타겟 모듈을 지정합니다.\n",
    "    bias=\"none\",  # 바이어스를 지원합니다.\n",
    "    # True 또는 \"unsloth\"를 사용하여 매우 긴 컨텍스트에 대해 VRAM을 30% 덜 사용하고, 2배 더 큰 배치 크기를 지원합니다.\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,  # 난수 상태를 설정합니다. # 공식 : 3407\n",
    "    use_rslora=True,  # 순위 안정화 LoRA를 지원합니다.\n",
    "    loftq_config=None,  # LoftQ를 지원합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# 총 스텝 수 계산\n",
    "total_steps = len(train_dataset) // (4 * 4)  # batch_size * gradient_accumulation_steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # 배치 설정\n",
    "    per_device_train_batch_size=4,       # 훈련 시 배치 사이즈\n",
    "    per_device_eval_batch_size=4,        # 평가 시 배치 사이즈\n",
    "    gradient_accumulation_steps=4,       # gradient 누적 단계 수 (메모리 최적화)\n",
    "\n",
    "    # 웜업 및 에폭\n",
    "    warmup_ratio=0.1,                    # 전체 스텝 대비 warmup 비율\n",
    "    num_train_epochs=1,                  # 총 학습 에폭 수\n",
    "\n",
    "    # 최적화 및 학습률 스케줄링\n",
    "    learning_rate=2e-4,                  # 초기 학습률\n",
    "    optim=\"adamw_bnb_8bit\",              # 8비트 AdamW 최적화\n",
    "    weight_decay=0.01,                   # 가중치 감소율\n",
    "    lr_scheduler_type=\"cosine\",          # 코사인 학습률 스케줄러\n",
    "    # lr_scheduler_type=\"cosine_with_restarts\",  # 코사인 스케줄러에 재시작 추가 가능\n",
    "\n",
    "    # 하드웨어 호환이 필요한 최적화\n",
    "    fp16=not torch.cuda.is_bf16_supported(),  # FP16 사용 (BF16 미지원 시)\n",
    "    bf16=torch.cuda.is_bf16_supported(),      # BF16 사용 (지원 시)\n",
    "    torch_compile=True,                       # PyTorch 컴파일을 통한 메모리, 학습 최적화\n",
    "\n",
    "    # 로깅 및 wandb\n",
    "    logging_steps=total_steps // 20,       # 전체 스텝의 5%마다 로깅\n",
    "    report_to=\"wandb\",                    # wandb\n",
    "    run_name=\"KMMLU_ALL_CATEGORIES\",      # run 이름\n",
    "\n",
    "    # 평가 및 체크포인트\n",
    "    eval_strategy=\"steps\",                # 정기적인 평가\n",
    "    eval_steps=total_steps // 20,         # 전체 스텝의 5%마다 평가\n",
    "    load_best_model_at_end=True,          # 최고 성능 모델 저장\n",
    "    metric_for_best_model=\"eval_loss\",    # 성능 평가 기준 (loss)\n",
    "    greater_is_better=False,              # 낮은 loss가 더 좋은 모델로 평가\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    save_strategy=\"steps\",                # 체크포인트 저장 전략 (스텝 단위)\n",
    "    save_steps=total_steps // 20,         # 전체 스텝의 5%마다 저장\n",
    "    save_total_limit=5,                   # 최대 체크포인트 저장 개수\n",
    "\n",
    "    # 기타 설정\n",
    "    seed=3407,                            # 시드 고정\n",
    "    output_dir=\"outputs\",                 # 출력 경로\n",
    "    max_grad_norm=1.0,                    # 최대 gradient norm 설정\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    dataset_num_proc=4,\n",
    "    packing=False,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmmlu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
